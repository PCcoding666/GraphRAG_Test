19:29:37,932 graphrag.index.cli INFO Logging enabled at /home/pcuser/Myproject/ragtest/output/20241003-192937/reports/indexing-engine.log
19:29:37,934 graphrag.index.cli INFO Starting pipeline run for: 20241003-192937, dryrun=False
19:29:37,934 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "qwen2:7b",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 3600.0,
        "api_base": "http://127.0.0.1:11434/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 5,
        "max_retry_wait": 60.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 5
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 10
    },
    "async_mode": "threaded",
    "root_dir": "/home/pcuser/Myproject/ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "/home/pcuser/Myproject/ragtest/output/20241003-192937/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/home/pcuser/Myproject/ragtest/output/20241003-192937/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai",
            "model": "qwen2:7b",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 5,
            "max_retry_wait": 60.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 5
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "qwen2:7b",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3600.0,
            "api_base": "http://127.0.0.1:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 5,
            "max_retry_wait": 60.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 5
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "qwen2:7b",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3600.0,
            "api_base": "http://127.0.0.1:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 5,
            "max_retry_wait": 60.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 5
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "qwen2:7b",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3600.0,
            "api_base": "http://127.0.0.1:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 5,
            "max_retry_wait": 60.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 5
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "qwen2:7b",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3600.0,
            "api_base": "http://127.0.0.1:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 5,
            "max_retry_wait": 60.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 5
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
19:29:37,936 graphrag.index.create_pipeline_config INFO skipping workflows 
19:29:37,936 graphrag.index.run.run INFO Running pipeline
19:29:37,936 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at /home/pcuser/Myproject/ragtest/output/20241003-192937/artifacts
19:29:37,936 graphrag.index.input.load_input INFO loading input from root_dir=input
19:29:37,936 graphrag.index.input.load_input INFO using file storage for input
19:29:37,937 graphrag.index.storage.file_pipeline_storage INFO search /home/pcuser/Myproject/ragtest/input for files matching .*\.txt$
19:29:37,938 graphrag.index.input.text INFO found text files from input, found [('book.txt', {})]
19:29:37,941 graphrag.index.input.text INFO Found 1 files, loading 1
19:29:37,943 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'create_final_relationships', 'create_final_text_units', 'create_final_community_reports', 'create_base_documents', 'create_final_documents']
19:29:37,943 graphrag.index.run.run INFO Final # of rows loaded: 1
19:29:38,42 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
19:29:38,45 datashaper.workflow.workflow INFO executing verb orderby
19:29:38,49 datashaper.workflow.workflow INFO executing verb zip
19:29:38,51 datashaper.workflow.workflow INFO executing verb aggregate_override
19:29:38,57 datashaper.workflow.workflow INFO executing verb chunk
19:29:38,180 datashaper.workflow.workflow INFO executing verb select
19:29:38,184 datashaper.workflow.workflow INFO executing verb unroll
19:29:38,192 datashaper.workflow.workflow INFO executing verb rename
19:29:38,195 datashaper.workflow.workflow INFO executing verb genid
19:29:38,200 datashaper.workflow.workflow INFO executing verb unzip
19:29:38,203 datashaper.workflow.workflow INFO executing verb copy
19:29:38,205 datashaper.workflow.workflow INFO executing verb filter
19:29:38,216 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
19:29:38,338 graphrag.index.run.workflow INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
19:29:38,339 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
19:29:38,362 datashaper.workflow.workflow INFO executing verb entity_extract
19:29:38,369 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://127.0.0.1:11434/v1
19:29:38,385 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for qwen2:7b: TPM=0, RPM=0
19:29:38,385 graphrag.index.llm.load_llm INFO create concurrency limiter for qwen2:7b: 5
19:30:01,3 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:30:01,9 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.60319175399991. input_tokens=2234, output_tokens=430
19:30:06,411 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:30:06,412 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.02000500799977. input_tokens=2233, output_tokens=229
19:30:24,215 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:30:24,216 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 45.81826420000016. input_tokens=2234, output_tokens=768
19:30:42,236 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:30:42,237 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 63.835833057999935. input_tokens=2234, output_tokens=752
19:30:50,638 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:30:50,639 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 72.23925371999985. input_tokens=2235, output_tokens=342
19:30:58,466 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:30:58,467 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.457230811000045. input_tokens=2233, output_tokens=341
19:31:04,662 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:31:04,663 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 58.250860873999954. input_tokens=2232, output_tokens=254
19:31:11,583 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:31:11,584 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 47.36689788900003. input_tokens=2234, output_tokens=291
19:31:17,593 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:31:17,594 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 35.356694492000315. input_tokens=2234, output_tokens=253
19:31:21,732 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:31:21,733 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.09407629899988. input_tokens=2233, output_tokens=163
19:31:27,33 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:31:27,33 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.566089830000237. input_tokens=2233, output_tokens=224
19:31:29,118 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:31:29,119 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.455311952000102. input_tokens=2235, output_tokens=77
19:31:37,990 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:31:37,991 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.407078402000025. input_tokens=2234, output_tokens=385
19:31:44,34 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:31:44,35 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.440021277999676. input_tokens=2234, output_tokens=246
19:31:50,671 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:31:50,672 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.938648706000095. input_tokens=2234, output_tokens=282
19:31:56,408 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:31:56,409 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.375401709000016. input_tokens=2233, output_tokens=241
19:32:00,526 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:32:00,527 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.40749536999965. input_tokens=2234, output_tokens=169
19:32:08,762 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:32:08,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.77068821900002. input_tokens=2234, output_tokens=346
19:32:14,938 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:32:14,939 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.90368237299981. input_tokens=2234, output_tokens=260
19:32:19,154 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:32:19,155 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.482410931999766. input_tokens=2234, output_tokens=168
19:32:24,859 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:32:24,860 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.44977664599992. input_tokens=2231, output_tokens=238
19:32:33,62 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:32:33,63 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.53588389200013. input_tokens=2234, output_tokens=359
19:32:40,708 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:32:40,709 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.9463999579998. input_tokens=2234, output_tokens=327
19:32:45,470 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:32:45,471 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.53225767799995. input_tokens=2234, output_tokens=201
19:32:51,120 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:32:51,121 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.965509955000016. input_tokens=2234, output_tokens=242
19:32:57,362 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:32:57,363 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.50295683200011. input_tokens=2234, output_tokens=262
19:33:07,487 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:33:07,489 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.42501255299976. input_tokens=2234, output_tokens=445
19:33:11,794 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:33:11,795 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.0851418999996. input_tokens=2234, output_tokens=174
19:33:17,557 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:33:17,557 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.08566472500024. input_tokens=2234, output_tokens=247
19:33:24,826 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:33:24,827 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.70570678800004. input_tokens=2234, output_tokens=302
19:33:29,868 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:33:29,869 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.50573163900026. input_tokens=2234, output_tokens=213
19:33:34,264 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:33:34,265 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.775855846000013. input_tokens=2234, output_tokens=180
19:33:39,200 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:33:39,200 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.404942200000278. input_tokens=2233, output_tokens=194
19:33:45,927 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:33:45,929 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.37049540399994. input_tokens=2234, output_tokens=279
19:33:50,949 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:33:50,950 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.12213100500003. input_tokens=2234, output_tokens=207
19:33:57,75 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:33:57,76 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.20632675800016. input_tokens=2233, output_tokens=260
19:34:05,249 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:05,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.984318863000226. input_tokens=2234, output_tokens=334
19:34:11,203 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:11,204 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.00293383999997. input_tokens=2232, output_tokens=233
19:34:15,287 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:15,287 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.358237085999917. input_tokens=2234, output_tokens=157
19:34:19,393 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:19,394 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.443400203000238. input_tokens=2233, output_tokens=160
19:34:23,428 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:23,428 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.35215979500026. input_tokens=2234, output_tokens=164
19:34:28,98 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:28,99 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.8483044300001. input_tokens=2234, output_tokens=184
19:34:32,255 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:32,256 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 21.051835108999967. input_tokens=2234, output_tokens=168
19:34:36,204 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:36,205 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.91724024799987. input_tokens=2234, output_tokens=161
19:34:39,781 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:39,782 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.3877405369999. input_tokens=2234, output_tokens=144
19:34:44,408 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:44,408 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.979565876999914. input_tokens=2233, output_tokens=191
19:34:49,944 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:49,945 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 21.845515195999724. input_tokens=2235, output_tokens=222
19:34:54,627 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:54,628 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.371523703000094. input_tokens=2234, output_tokens=191
19:34:58,900 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:34:58,901 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.695604715000172. input_tokens=2234, output_tokens=169
19:35:02,610 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:02,611 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.828673666000213. input_tokens=2234, output_tokens=144
19:35:07,721 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:07,722 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.31300523400023. input_tokens=2234, output_tokens=207
19:35:12,725 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:12,725 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.780369226999937. input_tokens=2234, output_tokens=203
19:35:18,588 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:18,588 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.95987059700019. input_tokens=2233, output_tokens=249
19:35:22,632 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:22,633 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.731279524. input_tokens=2234, output_tokens=160
19:35:27,335 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:27,336 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.724946674999956. input_tokens=2234, output_tokens=185
19:35:33,517 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:33,518 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.795371185000022. input_tokens=2234, output_tokens=262
19:35:39,143 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:39,144 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.417752685999858. input_tokens=2233, output_tokens=242
19:35:46,171 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:46,172 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.583532435000052. input_tokens=2232, output_tokens=302
19:35:50,163 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:50,164 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.53071079600022. input_tokens=2234, output_tokens=154
19:35:55,291 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:55,292 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.95527821199994. input_tokens=2234, output_tokens=208
19:35:59,423 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:35:59,423 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.905095095999968. input_tokens=2234, output_tokens=161
19:36:03,94 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:03,95 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.950594551999984. input_tokens=2234, output_tokens=145
19:36:08,453 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:08,454 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.28104132699991. input_tokens=2235, output_tokens=217
19:36:13,423 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:13,424 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.259420121999938. input_tokens=2234, output_tokens=202
19:36:18,793 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:18,794 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.501569448999817. input_tokens=2233, output_tokens=225
19:36:23,214 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:23,215 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.790954927000257. input_tokens=2234, output_tokens=184
19:36:27,174 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:27,175 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.080157739999777. input_tokens=2234, output_tokens=163
19:36:30,950 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:30,951 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.496391250000215. input_tokens=2234, output_tokens=155
19:36:35,838 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:35,838 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.41421223799989. input_tokens=2234, output_tokens=199
19:36:41,518 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:41,519 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.7247248890003. input_tokens=2234, output_tokens=238
19:36:47,360 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:47,361 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.146006625000155. input_tokens=2234, output_tokens=254
19:36:52,118 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:52,119 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.94368793900003. input_tokens=2233, output_tokens=202
19:36:56,788 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:36:56,788 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.83710661899977. input_tokens=2235, output_tokens=201
19:37:02,911 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:37:02,912 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.073225419999744. input_tokens=2234, output_tokens=267
19:37:10,697 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:37:10,698 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.178244647000156. input_tokens=2234, output_tokens=346
19:37:17,111 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:37:17,112 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.750682554999912. input_tokens=2234, output_tokens=279
19:37:21,538 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:37:21,539 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.41886664499998. input_tokens=2234, output_tokens=187
19:37:26,853 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:37:26,854 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.064872971000113. input_tokens=2234, output_tokens=232
19:37:33,770 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:37:33,771 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.85847012000022. input_tokens=2234, output_tokens=305
19:37:43,441 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:37:43,442 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.74344053999994. input_tokens=2234, output_tokens=432
19:37:49,820 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:37:49,821 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.70819328000016. input_tokens=2234, output_tokens=269
19:37:56,67 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:37:56,68 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.528736950000166. input_tokens=2234, output_tokens=270
19:38:00,530 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:38:00,531 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.6771498019998. input_tokens=2234, output_tokens=192
19:38:08,875 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:38:08,875 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 35.10393254199971. input_tokens=2234, output_tokens=367
19:38:16,250 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:38:16,251 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.80846856800008. input_tokens=2234, output_tokens=321
19:38:20,936 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:38:20,937 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.115722726999593. input_tokens=2234, output_tokens=199
19:38:25,244 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:38:25,245 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.17650612000034. input_tokens=2234, output_tokens=183
19:38:31,288 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:38:31,289 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.757594559000154. input_tokens=2233, output_tokens=264
19:38:37,27 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:38:37,28 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.151960578999933. input_tokens=2233, output_tokens=251
19:38:43,858 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:38:43,858 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.60701587199992. input_tokens=2234, output_tokens=297
19:38:49,110 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:38:49,111 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.17332294500011. input_tokens=2234, output_tokens=221
19:38:54,651 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:38:54,652 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.40650499100002. input_tokens=2234, output_tokens=229
19:39:01,63 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:39:01,63 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.773810610000055. input_tokens=2234, output_tokens=267
19:39:04,197 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:39:04,197 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.16923892299974. input_tokens=2234, output_tokens=127
19:39:08,616 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:39:08,617 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.758053264999944. input_tokens=2234, output_tokens=176
19:39:15,704 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:39:15,705 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.5935348160001. input_tokens=2233, output_tokens=296
19:39:20,860 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:39:20,861 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.209107676000258. input_tokens=2234, output_tokens=201
19:39:26,797 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:39:26,798 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.733887933000005. input_tokens=2235, output_tokens=231
19:39:33,509 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:39:33,509 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.311406962000092. input_tokens=2234, output_tokens=269
19:39:39,902 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:39:39,903 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.28584841799966. input_tokens=2234, output_tokens=257
19:39:49,702 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:39:49,703 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.997100904000035. input_tokens=2234, output_tokens=431
19:39:53,793 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:39:53,794 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.931717135000326. input_tokens=2232, output_tokens=170
19:40:00,450 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:40:00,451 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.65264050800033. input_tokens=2234, output_tokens=266
19:40:05,139 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:40:05,140 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.63035575699996. input_tokens=2234, output_tokens=183
19:40:11,307 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:40:11,307 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.40386013499983. input_tokens=2233, output_tokens=248
19:40:15,353 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:40:15,354 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.650705503000154. input_tokens=2234, output_tokens=157
19:40:25,504 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:40:25,505 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.71042274199999. input_tokens=2234, output_tokens=436
19:40:32,653 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:40:32,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.20263340099973. input_tokens=2234, output_tokens=309
19:40:41,609 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:40:41,610 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 36.46918490400003. input_tokens=2234, output_tokens=373
19:40:49,617 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:40:49,618 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 38.30981857200004. input_tokens=2234, output_tokens=342
19:40:53,767 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:40:53,768 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 38.41369908500019. input_tokens=2234, output_tokens=158
19:40:58,309 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:40:58,310 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.80456438400006. input_tokens=2234, output_tokens=183
19:41:02,166 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:41:02,166 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.511790527000358. input_tokens=2234, output_tokens=156
19:41:06,527 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:41:06,528 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.917919079000058. input_tokens=2234, output_tokens=177
19:41:13,823 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:41:13,824 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.205270663000192. input_tokens=2233, output_tokens=312
19:41:21,528 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:41:21,529 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.760379295999883. input_tokens=2234, output_tokens=308
19:41:28,122 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:41:28,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.813168758999836. input_tokens=2233, output_tokens=270
19:41:35,586 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:41:35,587 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.41985884099995. input_tokens=2233, output_tokens=315
19:41:41,819 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:41:41,820 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 35.291504282999995. input_tokens=2233, output_tokens=251
19:41:48,748 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:41:48,749 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.9252546849998. input_tokens=2234, output_tokens=293
19:41:57,746 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:41:57,748 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 36.21817852200002. input_tokens=2234, output_tokens=390
19:42:04,826 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:42:04,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 36.70417265800006. input_tokens=2235, output_tokens=296
19:42:09,981 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:42:09,982 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.395080618000065. input_tokens=2234, output_tokens=210
19:42:20,437 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:42:20,438 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 38.61743864099981. input_tokens=2234, output_tokens=434
19:42:26,316 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:42:26,317 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 37.56736181999986. input_tokens=2234, output_tokens=250
19:42:31,428 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:42:31,428 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.680378090999966. input_tokens=2233, output_tokens=214
19:42:36,858 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:42:36,859 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.03027902099984. input_tokens=2234, output_tokens=226
19:42:43,948 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:42:43,949 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.966628315999515. input_tokens=2234, output_tokens=300
19:42:50,440 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:42:50,441 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.002567487000306. input_tokens=2234, output_tokens=272
19:42:58,461 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:42:58,461 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.14394837100008. input_tokens=2233, output_tokens=350
19:43:03,979 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:03,980 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.55118182900014. input_tokens=2234, output_tokens=225
19:43:09,822 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:09,823 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.96368724799959. input_tokens=2234, output_tokens=233
19:43:18,64 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:18,65 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.114847166999425. input_tokens=2234, output_tokens=364
19:43:22,499 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:22,500 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.05817364399991. input_tokens=2234, output_tokens=180
19:43:27,143 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:27,144 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.681792964000124. input_tokens=2234, output_tokens=191
19:43:32,828 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:32,829 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.84799416700025. input_tokens=2234, output_tokens=239
19:43:37,299 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:37,299 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.475651766999363. input_tokens=2233, output_tokens=178
19:43:41,23 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:41,24 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.95907245499984. input_tokens=2234, output_tokens=148
19:43:48,350 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:48,351 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.85068944500017. input_tokens=2234, output_tokens=303
19:43:53,276 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:53,276 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.132142458999624. input_tokens=2234, output_tokens=197
19:43:56,851 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:43:56,851 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.022497329000544. input_tokens=2233, output_tokens=142
19:44:03,355 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:44:03,356 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.05646729700038. input_tokens=2234, output_tokens=275
19:44:12,242 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:44:12,243 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.218341709000015. input_tokens=2234, output_tokens=389
19:44:16,916 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:44:16,916 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.565187404000426. input_tokens=2234, output_tokens=192
19:44:23,35 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:44:23,36 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.759018910000123. input_tokens=2233, output_tokens=254
19:44:29,196 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:44:29,197 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.34512145999997. input_tokens=2234, output_tokens=245
19:44:37,686 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:44:37,686 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.3295785600003. input_tokens=2234, output_tokens=360
19:44:43,509 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:44:43,510 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.266719319000003. input_tokens=2234, output_tokens=247
19:44:46,950 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:44:46,951 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.033898242999385. input_tokens=2235, output_tokens=136
19:44:51,869 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:44:51,870 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.83330630099954. input_tokens=2234, output_tokens=195
19:44:57,797 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:44:57,797 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.5999888260003. input_tokens=2234, output_tokens=246
19:45:02,532 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:45:02,532 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.845609026999227. input_tokens=2234, output_tokens=189
19:45:08,952 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:45:08,953 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.44248997500017. input_tokens=2234, output_tokens=263
19:45:15,560 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:45:15,561 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.609548136999365. input_tokens=2235, output_tokens=270
19:45:20,707 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:45:20,708 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.83803628500027. input_tokens=2233, output_tokens=200
19:45:27,475 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:45:27,475 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.677594392000174. input_tokens=2234, output_tokens=262
19:45:34,256 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:45:34,257 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.72440948900021. input_tokens=2234, output_tokens=279
19:45:38,956 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:45:38,957 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.003075815000557. input_tokens=2234, output_tokens=187
19:45:43,454 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:45:43,455 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.893673542000215. input_tokens=2234, output_tokens=170
19:45:47,491 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:45:47,492 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.783306903000266. input_tokens=2234, output_tokens=165
19:45:53,542 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:45:53,543 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.067500312999982. input_tokens=2233, output_tokens=250
19:46:02,393 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:46:02,394 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.135886705000303. input_tokens=2233, output_tokens=360
19:46:09,548 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:46:09,549 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.59204539700022. input_tokens=2234, output_tokens=295
19:46:13,328 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:46:13,329 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.873467605999394. input_tokens=2234, output_tokens=152
19:46:19,443 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:46:19,444 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.951402063000387. input_tokens=2234, output_tokens=258
19:46:27,538 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:46:27,539 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.99482617800004. input_tokens=2234, output_tokens=344
19:46:35,168 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:46:35,168 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.77438609300043. input_tokens=2234, output_tokens=317
19:46:43,399 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:46:43,400 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.85020168200026. input_tokens=2234, output_tokens=330
19:46:50,91 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:46:50,91 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 36.76211989999956. input_tokens=2234, output_tokens=268
19:46:58,224 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:46:58,225 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 38.78047009399961. input_tokens=2234, output_tokens=332
19:47:06,402 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:06,403 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 38.863663821000046. input_tokens=2234, output_tokens=330
19:47:13,18 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:13,19 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 37.84988023400001. input_tokens=2234, output_tokens=278
19:47:17,832 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:17,832 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.43190654799946. input_tokens=2234, output_tokens=186
19:47:24,260 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:24,261 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.16885499399996. input_tokens=2234, output_tokens=263
19:47:28,799 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:28,800 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.575071446000038. input_tokens=2234, output_tokens=187
19:47:31,664 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:31,665 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.261641123999652. input_tokens=2234, output_tokens=113
19:47:36,44 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:36,44 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.02504588500051. input_tokens=2233, output_tokens=169
19:47:40,674 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:40,674 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.84151934199963. input_tokens=2233, output_tokens=189
19:47:45,538 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:45,539 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 21.2779761110005. input_tokens=2233, output_tokens=203
19:47:50,541 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:50,541 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 21.740987306000534. input_tokens=2234, output_tokens=206
19:47:57,896 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:47:57,897 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.23103502199956. input_tokens=2234, output_tokens=314
19:48:09,271 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:48:09,272 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.227028466000775. input_tokens=2234, output_tokens=493
19:48:17,629 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:48:17,630 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 36.95556931499959. input_tokens=2234, output_tokens=350
19:48:23,649 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:48:23,649 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 38.10991279399968. input_tokens=2233, output_tokens=252
19:48:30,840 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:48:30,841 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 40.298627263000526. input_tokens=2233, output_tokens=316
19:48:36,358 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:48:36,358 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 38.46140354199997. input_tokens=2234, output_tokens=232
19:48:41,443 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:48:41,444 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.17132809600025. input_tokens=2233, output_tokens=213
19:48:47,112 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:48:47,112 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.48165386800065. input_tokens=2235, output_tokens=229
19:48:52,820 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:48:52,821 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.17078343600042. input_tokens=2234, output_tokens=237
19:49:03,886 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:03,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.04533275600079. input_tokens=2233, output_tokens=479
19:49:09,641 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:09,641 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.282485179000105. input_tokens=2234, output_tokens=241
19:49:14,666 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:14,667 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.22257193299993. input_tokens=2234, output_tokens=210
19:49:21,912 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:21,913 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.79998348499976. input_tokens=2234, output_tokens=292
19:49:26,355 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:26,356 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.535139372999765. input_tokens=2234, output_tokens=185
19:49:32,456 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:32,457 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.569811803999983. input_tokens=2231, output_tokens=248
19:49:38,137 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:38,138 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.49604697199993. input_tokens=2234, output_tokens=242
19:49:44,644 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:44,645 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.977613424000083. input_tokens=2234, output_tokens=282
19:49:47,999 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:47,999 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.086007874000643. input_tokens=2234, output_tokens=140
19:49:53,827 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:53,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.470916962000047. input_tokens=2234, output_tokens=255
19:49:59,331 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:49:59,332 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.87461435500063. input_tokens=2234, output_tokens=242
19:50:03,978 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:50:03,979 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.840279919999375. input_tokens=2233, output_tokens=200
19:50:07,841 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:50:07,841 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.196379285999683. input_tokens=2234, output_tokens=163
19:50:14,548 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:50:14,548 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.548564343999715. input_tokens=2234, output_tokens=298
19:50:19,130 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:50:19,131 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.303343980000136. input_tokens=2234, output_tokens=195
19:50:28,476 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:50:28,477 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.144653472000755. input_tokens=2233, output_tokens=415
19:50:32,86 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:50:32,87 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.107853762999184. input_tokens=2234, output_tokens=146
19:50:39,206 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:50:39,207 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.364900631000637. input_tokens=2234, output_tokens=309
19:50:43,644 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:50:43,645 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.09641038599966. input_tokens=2234, output_tokens=191
19:50:50,21 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:50:50,22 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.890111968999918. input_tokens=2234, output_tokens=276
19:50:56,450 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:50:56,451 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.973558226000023. input_tokens=2233, output_tokens=278
19:51:00,761 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:00,761 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.6741479049997. input_tokens=2233, output_tokens=181
19:51:03,923 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:03,923 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.716202354000416. input_tokens=2234, output_tokens=128
19:51:07,407 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:07,408 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.76254749399959. input_tokens=2234, output_tokens=144
19:51:11,405 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:11,406 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 21.383643917999507. input_tokens=2234, output_tokens=166
19:51:19,211 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:19,212 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.76110288200016. input_tokens=2234, output_tokens=347
19:51:23,428 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:23,428 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.66660159999992. input_tokens=2234, output_tokens=180
19:51:26,808 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:26,808 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.88467601299999. input_tokens=2234, output_tokens=138
19:51:30,454 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:30,454 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.045912425000097. input_tokens=2233, output_tokens=153
19:51:37,865 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:37,866 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.459790351000265. input_tokens=2233, output_tokens=325
19:51:45,912 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:45,913 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.70026727700042. input_tokens=2234, output_tokens=353
19:51:50,661 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:50,661 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 27.232591039999534. input_tokens=2234, output_tokens=199
19:51:55,479 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:51:55,479 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.670542362999186. input_tokens=2234, output_tokens=202
19:52:00,248 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:00,249 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.794407963000594. input_tokens=2234, output_tokens=202
19:52:05,997 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:05,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.131363290999616. input_tokens=2234, output_tokens=244
19:52:14,955 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:14,956 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.042402189999848. input_tokens=2232, output_tokens=394
19:52:22,907 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:22,908 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.24598580300062. input_tokens=2234, output_tokens=350
19:52:28,616 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:28,617 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.13679032099935. input_tokens=2234, output_tokens=249
19:52:35,655 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:35,656 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 35.40589708600055. input_tokens=2232, output_tokens=302
19:52:41,269 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:41,270 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 35.271502413000235. input_tokens=2234, output_tokens=242
19:52:44,805 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:44,805 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.848812866000117. input_tokens=2234, output_tokens=148
19:52:49,665 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:49,666 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.757295050999346. input_tokens=2088, output_tokens=214
19:52:49,677 datashaper.workflow.workflow INFO executing verb merge_graphs
19:52:49,711 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
19:52:49,902 graphrag.index.run.workflow INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
19:52:49,903 graphrag.utils.storage INFO read table from storage: create_base_extracted_entities.parquet
19:52:49,914 datashaper.workflow.workflow INFO executing verb summarize_descriptions
19:52:52,558 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:52,559 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.628378847000022. input_tokens=341, output_tokens=101
19:52:54,964 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:54,964 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.032678313999895. input_tokens=296, output_tokens=105
19:52:56,542 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:56,543 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.609913820000656. input_tokens=177, output_tokens=66
19:52:57,804 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:52:57,805 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 7.870247060999645. input_tokens=175, output_tokens=50
19:53:00,66 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:00,67 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.138165039000341. input_tokens=303, output_tokens=94
19:53:01,167 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:01,168 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.608677916000488. input_tokens=173, output_tokens=43
19:53:10,993 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:10,994 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 16.029005279999183. input_tokens=3753, output_tokens=360
19:53:18,57 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:18,58 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 21.51407127499988. input_tokens=224, output_tokens=323
19:53:19,391 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:19,391 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 21.586276468000506. input_tokens=175, output_tokens=54
19:53:23,897 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:23,898 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.831143294999492. input_tokens=169, output_tokens=209
19:53:26,290 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:26,291 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 25.12275322900041. input_tokens=170, output_tokens=108
19:53:31,52 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:31,53 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 20.05856847799987. input_tokens=174, output_tokens=218
19:53:32,346 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:32,347 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.288544846999685. input_tokens=190, output_tokens=54
19:53:34,300 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:34,301 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.909185569999863. input_tokens=172, output_tokens=83
19:53:37,83 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:37,83 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 13.18479443599972. input_tokens=199, output_tokens=122
19:53:38,380 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:38,381 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 12.089800806999847. input_tokens=172, output_tokens=55
19:53:41,311 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:41,312 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.258308939000017. input_tokens=233, output_tokens=131
19:53:42,659 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:42,660 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.31299227799991. input_tokens=178, output_tokens=57
19:53:43,397 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:43,398 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.096662990000368. input_tokens=171, output_tokens=28
19:53:44,839 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:44,840 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 7.756192625999574. input_tokens=174, output_tokens=60
19:53:46,579 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:46,579 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.198287399000037. input_tokens=206, output_tokens=74
19:53:51,498 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:51,499 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.187231464999968. input_tokens=437, output_tokens=216
19:53:54,447 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:54,448 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 11.78765921700051. input_tokens=280, output_tokens=132
19:53:57,117 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:57,118 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 13.719640579999577. input_tokens=179, output_tokens=120
19:53:59,617 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:53:59,617 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.777129766000144. input_tokens=231, output_tokens=111
19:54:04,573 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:04,574 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 17.993761462000293. input_tokens=513, output_tokens=215
19:54:07,758 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:07,758 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 16.25887343100021. input_tokens=223, output_tokens=145
19:54:10,232 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:10,233 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 15.784774294999806. input_tokens=170, output_tokens=112
19:54:11,508 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:11,509 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.39049821899971. input_tokens=165, output_tokens=56
19:54:12,675 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:12,676 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 13.058218827000019. input_tokens=161, output_tokens=51
19:54:15,762 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:15,763 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 11.18924318900008. input_tokens=209, output_tokens=137
19:54:18,253 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:18,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.495368581000548. input_tokens=245, output_tokens=104
19:54:22,658 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:22,659 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 12.425737498000672. input_tokens=172, output_tokens=194
19:54:28,111 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:28,111 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 16.602426424999976. input_tokens=215, output_tokens=245
19:54:29,148 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:29,149 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 16.472954425000353. input_tokens=171, output_tokens=42
19:54:30,335 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:30,336 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.572237414000483. input_tokens=165, output_tokens=49
19:54:36,80 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:36,81 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 17.826479096000185. input_tokens=179, output_tokens=255
19:54:37,535 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:37,536 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.876620353000362. input_tokens=175, output_tokens=58
19:54:41,687 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:41,688 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 13.575672451000173. input_tokens=199, output_tokens=179
19:54:43,481 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:43,481 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.331847854999978. input_tokens=191, output_tokens=77
19:54:47,504 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:47,505 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 17.168686592000086. input_tokens=359, output_tokens=171
19:54:52,462 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:52,463 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 16.381171484999868. input_tokens=201, output_tokens=212
19:54:54,543 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:54,543 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 17.00694162399941. input_tokens=219, output_tokens=87
19:54:56,943 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:56,944 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 15.255991861999973. input_tokens=270, output_tokens=101
19:54:58,831 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:54:58,832 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 15.350183065999772. input_tokens=183, output_tokens=76
19:55:01,320 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:01,321 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 13.815739619000851. input_tokens=226, output_tokens=104
19:55:04,584 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:04,585 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 12.122016213999814. input_tokens=231, output_tokens=142
19:55:08,457 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:08,457 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 13.913515906999237. input_tokens=174, output_tokens=159
19:55:11,624 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:11,625 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.680314234999969. input_tokens=210, output_tokens=133
19:55:13,841 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:13,841 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 15.009168149000288. input_tokens=204, output_tokens=95
19:55:15,773 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:15,774 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.452850152000792. input_tokens=184, output_tokens=80
19:55:17,500 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:17,500 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 12.914852345000327. input_tokens=160, output_tokens=73
19:55:18,905 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:18,906 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.448240370000349. input_tokens=162, output_tokens=58
19:55:21,46 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:21,47 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.422259140000278. input_tokens=185, output_tokens=91
19:55:23,274 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:23,275 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.433260403000531. input_tokens=297, output_tokens=91
19:55:25,320 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:25,321 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.546809225000288. input_tokens=219, output_tokens=85
19:55:27,210 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:27,210 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.709924292999858. input_tokens=202, output_tokens=76
19:55:28,619 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:28,620 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.71374310200008. input_tokens=185, output_tokens=56
19:55:31,491 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:31,492 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.444220512999891. input_tokens=180, output_tokens=120
19:55:33,22 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:33,23 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.747511283000676. input_tokens=178, output_tokens=59
19:55:34,978 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:34,979 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.657331229000192. input_tokens=171, output_tokens=75
19:55:36,356 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:36,357 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.146050515999377. input_tokens=178, output_tokens=52
19:55:37,997 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:37,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.37782145700021. input_tokens=204, output_tokens=64
19:55:46,590 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:46,591 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 15.098694893999891. input_tokens=275, output_tokens=377
19:55:51,183 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:51,183 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 18.160140064999723. input_tokens=273, output_tokens=201
19:55:52,709 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:52,709 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 17.730221118999907. input_tokens=178, output_tokens=65
19:55:55,98 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:55:55,98 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 18.741329034000046. input_tokens=183, output_tokens=103
19:56:02,513 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:56:02,514 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 24.5149794200006. input_tokens=369, output_tokens=320
19:56:03,294 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:56:03,295 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 16.703178252000725. input_tokens=170, output_tokens=30
19:56:10,304 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:56:10,305 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 19.121084469999914. input_tokens=181, output_tokens=301
19:56:13,626 httpx INFO HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions "HTTP/1.1 200 OK"
19:56:13,627 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 20.917058612999426. input_tokens=179, output_tokens=131
19:56:13,638 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
19:56:13,750 graphrag.index.run.workflow INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
19:56:13,751 graphrag.utils.storage INFO read table from storage: create_summarized_entities.parquet
19:56:13,764 datashaper.workflow.workflow INFO executing verb cluster_graph
19:56:13,822 datashaper.workflow.workflow INFO executing verb select
19:56:13,824 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
19:56:13,945 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['create_base_entity_graph']
19:56:13,946 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
19:56:13,962 datashaper.workflow.workflow INFO executing verb unpack_graph
19:56:13,982 datashaper.workflow.workflow INFO executing verb rename
19:56:13,988 datashaper.workflow.workflow INFO executing verb select
19:56:13,994 datashaper.workflow.workflow INFO executing verb dedupe
19:56:14,1 datashaper.workflow.workflow INFO executing verb rename
19:56:14,7 datashaper.workflow.workflow INFO executing verb filter
19:56:14,26 datashaper.workflow.workflow INFO executing verb text_split
19:56:14,35 datashaper.workflow.workflow INFO executing verb drop
19:56:14,41 datashaper.workflow.workflow INFO executing verb merge
19:56:14,79 datashaper.workflow.workflow INFO executing verb text_embed
19:56:14,81 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://127.0.0.1:11434
19:56:14,138 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 298 inputs via 298 snippets using 19 batches. max_batch_size=16, max_tokens=8191
19:56:14,144 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"PROJECT GUTENBERG":"Project Gutenberg is an organization dedicated to distributing eBooks, with a focus on providing access to public domain books and texts. It operates under certain conditions concerning copyright status and requires users to check local laws before utilizing its materials. The organization produces and distributes free eBooks with the support of volunteers and promotes free access to electronic works, subject to specific terms of use and intellectual property agreements. Project Gutenberg also provides electronic works that are available for distribution without copyright royalties in the United States."', '"THE PROJECT GUTENBERG EBOOK A CHRISTMAS CAROL":"A Christmas Carol is a book produced by Project Gutenberg, indicating its digital availability and wide accessibility.") ("entity"', '"1958":"The year 1958 is mentioned without context, potentially marking the beginning or an event in a series of years." ) ("entity"', '"MR. FEZZIWIG":"Mr. Fezziwig is a kind-hearted, jovial old merchant.") ("entity"', '"MRS. CRATCHIT":"MRS. CRATCHIT is the protagonist of this scene and the matriarch of the Cratchit family from Charles Dickens\' \'A Christmas Carol\'. She is responsible for making gravy and addressing her children, indicating she\'s likely a housewife or caretaker in the household. Mrs. Cratchit warmly welcomes her family back home on Christmas Day and shows affection by kissing little Bob. She is concerned about her children being late for Christmas activities and dresses bravely in ribbons despite dressing poorly."', '"BOB CRATCHIT":"Bob Cratchit is a character known for expressing happiness and concern for Tiny Tim\'s memory. He also calmly states his opinion about the pudding, praising Mrs. Cratchit for her culinary skills and indicating his admiration and support. Despite his low income, Bob receives blessings from the Ghost of Christmas Present on Christmas Eve. As the father of Tiny Tim, he returns from church with his son anticipating their festive celebration. In a memorable scene, Bob is depicted sliding down a slide on Cornhill in honor of Christmas Eve."', '"JOE":"Joe is a character known for his interaction skills as he engages in conversations and activities with other individuals. He poses questions about taking down bed-curtains while someone is lying there, showcasing his curious nature. Moreover, Joe embodies the role of an individual who not only speaks but also handles the possessions of others during these interactions."', '"STAVE ONE":"STAVE ONE refers to the initial segment or chapter within a narrative or book, typically identified by its heading. In the context provided, STAVE ONE specifically denotes the commencement of Marley\'s Ghost, signifying the first part of the story."', '"MARLEY":"MARLEY refers to a deceased partner of Scrooge, whose demise holds considerable significance in their business relationship. The statement \'Marley was dead, to begin with\' confirms that Marley has passed away."', '"SCROOGE":Scrooge is a character who ponders on what the Ghost had said and questions the speed of the Ghost\'s travel.\nScrooge is a character who predicts that it would be necessary for him and the clerk to part.\nScrooge is a character who raises the salary of his employee and promises to assist his struggling family during Christmas.\nScrooge is a character who receives visits from ghosts and experiences changes in his attitude towards life and generosity.\nScrooge is a character who recognizes places from his past and feels joy upon seeing them.\nScrooge is a character who refuses to be friendly with his nephew despite the latter\'s attempts to reconcile.\nScrooge is a character who refuses to believe in ghosts until one appears before him.\nScrooge is a character who refuses to listen or be friendly towards others.\nScrooge is a character who requests payment from another person, showing his business nature.\nScrooge is a character who seeks guidance from an unseen spirit, expressing his willingness to undergo change and improve.\nScrooge is a character who regards everyone with a delighted smile and greets them warmly, despite his past reputation.\nScrooge is a character who significantly improves his behavior and attitude towards others, becoming kinder and more generous.\nScrooge is a character who seeks refuge or resource after being confronted with Doom.\nScrooge is a character who struggles with his thoughts about making choices based on gain or love.\nScrooge is a character who undergoes a transformation after being visited by the Spirit, experiencing horror at the sight of monstrous humans.\nScrooge is a character who undergoes a transformation after being visited by the Spirit, becoming more compassionate and understanding.\nScrooge is a main character who experiences encounters with ghosts and struggles to overcome them.', '"SOLE EXECUTOR", "SOLE ADMINISTRATOR", "SOLE ADMINISTRATOR":"These terms refer to Scrooge\'s role in managing Marley\'s affairs after his death, indicating that he had a significant organizational or administrative responsibility."', '"FUNERAL":"The funeral of Marley marks the end of his life and impacts on Scrooge\'s personal and professional life."', '"HIS OFFICE":"His office is depicted as being kept at a consistently low temperature even during the dog-days of summer."', '"BEGGARS":"Beggars" refers to individuals who seek help from others due to their inability to provide for themselves. In the context provided, there seems to be a discrepancy in Scrooge\'s behavior towards these "Beggars". Initially, it is stated that "Beggars are not able to get Scrooge\'s attention or assistance, indicating his lack of empathy towards them." This suggests that Scrooge does not show concern for the welfare of beggars and may be indifferent to their plight. However, another description contradicts this by stating that "Scrooge questions beggars, showing his interest and concern for those less fortunate." If we resolve these contradictions, it could imply that while Scrooge might initially appear uninterested or uncaring towards beggars, he does take the time to inquire about their circumstances, which suggests a level of interest and possibly empathy. Therefore, Scrooge\'s behavior towards "Beggars" seems to involve both indifference and some level of concern, depending on the context in which these interactions occur.', '"CHILDREN":Children in relation to Scrooge exhibit contrasting behaviors and perceptions. On one hand, it is suggested that Scrooge doesn\'t engage with children when they ask for assistance or information, implying he lacks concern for their needs ("Children also don\'t receive any interaction from Scrooge when asking for the time, suggesting he doesn\'t care about their needs either."). Conversely, there\'s a depiction of Scrooge interacting with children and finding pleasure in their presence and innocence ("Scrooge interacts with children, finding pleasure in their presence and innocence"). \n\nThe Children themselves are portrayed in different ways. They can be seen as wretched, abject, frightful, and miserable figures, symbolizing the degradation and perversion of humanity ("The Children are depicted as wretched, abject, frightful, and miserable figures, representing the degradation and perversion of humanity"). However, there\'s also a scene where children are running out into the snow to meet their married sisters, brothers, cousins, uncles, and aunts ("The children are running out into the snow to meet their married sisters, brothers, cousins, uncles, aunts").\n\nIn summary, Scrooge\'s interaction with children varies significantly depending on the context. He may either ignore them or find pleasure in their company. The Children themselves can be seen as symbols of human degradation or ordinary individuals enjoying social gatherings.\n\nPlease note that without more specific context about these descriptions and how they relate to each other (e.g., are they from different literary works, historical periods, etc.), it\'s challenging to provide a definitive interpretation or resolution of contradictions.', '"MAN AND WOMAN":"Neither men nor women are able to get directions from Scrooge, indicating his lack of social engagement or concern."']}
19:56:14,146 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"BLIND MEN\'S DOGS":"The blind men\'s dogs show awareness of Scrooge and avoid him by guiding their owners away, suggesting an aura of negativity around him."', '"NEPHEW":"The Nephew, portrayed as an individual seeking friendship with Scrooge, faces initial resistance from him. Despite this, he persistently advocates for maintaining a positive perspective towards Christmas and encourages Scrooge to embrace the spirit of the holiday in his own unique manner."', '"MERRY CHRISTMAS":"Merry Christmas" is a phrase associated with contrasting sentiments for Scrooge. On one hand, it\'s linked negatively to financial responsibilities and the sense of aging without accumulating wealth, reflecting his personal concerns and possibly past experiences. On the other hand, the celebration of Merry Christmas is depicted through imagery of sharing grog and singing songs, underscoring the human connection that can be found even in solitude or isolation. This dual nature of "Merry Christmas" encapsulates both the personal struggles and the universal warmth associated with this festive greeting.', '"CHRISTMAS-TIME":"Christmas-time is described as a good time characterized by kindness, forgiveness, charity and warmth.")  ("entity"', '"CLERK":The description provided pertains to "The Clerk", an individual employed by Scrooge. The first description states that this person earns fifteen shillings a week and has a family, while also being greeted cordially by Scrooge. This suggests that the relationship between Scrooge and his clerk is amicable despite the potentially challenging work environment.\n\nThe second description portrays "The Clerk" as an employee who works under Scrooge and is involved in shutting down the office alongside him. This implies a collaborative aspect to their working relationship, where they share responsibilities beyond just daily operations.\n\nIn summary, "The Clerk", depicted as an employee of Scrooge, earns fifteen shillings per week with familial obligations. Despite potentially demanding work conditions, there exists a cordial greeting from Scrooge towards him. Furthermore, this individual is involved in the process of shutting down the office alongside Scrooge, indicating shared responsibilities and perhaps a collaborative working relationship.\n\nPlease note that these descriptions might be taken out of context or may not fully represent the character\'s complete profile within their respective narratives.', '"BEDLAM":"\\"BEDLAM\\" refers to an asylum or institution for the mentally ill, which Scrooge associates with a state of mind akin to insanity. Simultaneously, it symbolizes his perception of others as lacking human qualities, particularly those who are less fortunate."', '"HIS CLERK":"His clerk is someone who works for Scrooge, discussing merry Christmas despite his low salary."', '"SCROOGE AND MARLEY\'S":"Scrooge and Marley\'s is the business owned by Scrooge and his partner Marley."', '"MR. SCROOGE":"Mr. Scrooge primarily refers to Ebenezer Scrooge, the central character in Charles Dickens\' classic novel \'A Christmas Carol.\' He is addressed directly by this term when speaking or referring to him. However, there\'s also a nuanced interpretation where Mr. Scrooge symbolizes an individual who has lost his partner and now finds himself alone, which brings distress to another character in the narrative."', '"MR. MARLEY":"Mr. Marley is the deceased partner of Scrooge in their business, mentioned by one of the gentlemen."', '"SEVEN YEARS AGO, THIS VERY NIGHT":"This event refers to the death of Mr. Marley seven years prior on that same date."', '"THE GENTLEMAN":"The Gentleman" refers to a person who is initially taken by surprise when approached by Scrooge. He agrees to see Scrooge despite this initial shock, demonstrating flexibility and openness. Additionally, "The Gentleman" embodies the role of a representative for various charitable organizations that are dedicated to advocating for the welfare of the poor and destitute. His involvement in charitable activities is further highlighted through his participation in fundraising efforts during Christmas, indicating his commitment to supporting those in need financially. In essence, "The Gentleman" combines elements of personal openness with a strong dedication to social responsibility and philanthropy.', '"THE TREADMILL AND THE POOR LAW":"These are two establishments that Scrooge is aware of being operational, suggesting they are part of a larger system he supports."', '"THE ESTABLISHMENTS":', '"GENTLEMEN":"The \'gentlemen\', referring to a group of individuals, approach Scrooge with inquiries regarding his aspirations for Christmas and his participation in philanthropic endeavors. Subsequently, these same \'gentlemen\' manage to convince Scrooge to abandon his pursuit of a certain objective."', '"CHRISTMAS":"Christmas represents a transformative period for Scrooge, marking a shift in his heart where he decides to honor this event throughout the year, reflecting on his life\'s change. It is also the time when Scrooge responds to questions about festivities and charity, highlighting its significance during this season. The essence of Christmas is further emphasized by the spirits visiting Scrooge, leading to a profound alteration in his perspective. This festive season is symbolized by the presence of Christmas toys and presents, indicating a celebration of joy and merriment. Additionally, Christmas is portrayed as a time for reunion, suggesting a joyful gathering that lasts throughout the entire festive period."']}
19:56:14,146 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"CHARITY":"Charity refers to Scrooge\'s stance on supporting establishments for those who are badly off, indicating his views on social responsibility."', '"CHURCH TOWER":"The ancient tower of a church is described as having a Gothic window and striking hours and quarters in clouds, symbolizing its age and grandeur."', '"LABOURERS":"The labourers are repairing gas-pipes on the main street corner."', '"RAGGED MEN AND BOYS":"A group consisting of ragged men and boys is depicted as being gathered around a fire, engaging in activities such as warming their hands and benefiting from its warmth. This scene suggests a sense of communal gathering or belonging, possibly indicative of an organization or community that these individuals are part of."', '"WATER-PLUG":"The water-plug is left in solitude, causing its overflowings to suddenly congeal and turn into ice."', '"POULTERERS\' AND GROCERS\':"These trades are described as becoming bright with holly sprigs and berries crackling in the lamp heat of their windows."', '"COUNTING-HOUSE":"A counting-house is a location where financial transactions take place, serving as the workplace for Scrooge and being integral to his business operations."', '"EXPECTANT CLERK":"The expectant clerk is someone who anticipates the end of work for the day and has to perform tasks related to shutting down operations."', '"THE KEY":"The key Scrooge has relinquished and then takes back indicates access control or security."', '"THE DOOR":"The door that Scrooge considers opening, but pauses before doing so due to a moment\'s irresolution."', '"MARLEY\'S PIGTAIL":"Marley\'s pigtail is mentioned as something that might stick out of the hall, suggesting an element of surprise or fear."', '"THE HOUSE":"The house where Scrooge resides and experiences echoes when he closes the door."', '"EVERY ROOM ABOVE":"Scrooge mentions every room above as experiencing separate peals of echoes, indicating a large or multi-level dwelling."', '"EVERY CASK IN THE WINE-MERCHANT\'S CELLARS BELOW":"The wine merchant\'s cellars are described as being below Scrooge\'s house and also experiencing echoes when he closes the door."', '"HALL":"The hall is the location where Scrooge walks up stairs and enters his rooms."', '"STAIRS":"Scrooge walks up the stairs, suggesting he\'s moving from one floor to another."']}
19:56:14,147 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"GAS-LAMPS":"The gas-lamps are a source of light that illuminates poorly, creating a dark environment for Scrooge."', '"ENTRY":"Scrooge is in the entryway or foyer when he notices darkness and the dip of his candle."', '"SITTING-ROOM":"The Sitting-room is a specific location in Scrooge\'s house where he conducts his nightly routine."', '"BEDROOM":"Scrooge\'s Bedroom serves as both his final destination and a point of concern after using the extinguisher-cap, symbolizing his return to his physical space. Additionally, it is also an important location in Scrooge\'s house where he meticulously checks for any unusual anomalies before retiring for bed."', '"LUMBER-ROOM":"The Lumber-room is a third specific location in Scrooge\'s house where he ensures everything is as it should be."', '"SAUCEPAN OF GRUEL":"A saucepan containing gruel, which Scrooge has due to having a cold."', '"COLD":"Scrooge\'s condition that necessitates the consumption of gruel."', '"DRESSING-GOWN":"A dressing-gown is an item of clothing that Scrooge puts on, suggesting he\'s preparing for bed or relaxation."', '"NIGHTCAP":"A nightcap is a type of headwear worn by Scrooge before going to sleep, indicating nighttime activities."', '"FIREPLACE":"The fireplace is an old Dutch merchant\'s creation that Scrooge uses for warmth on a cold night, highlighting the setting and its historical element."', '"GRUEL":"Gruel is the food Scrooge consumes, suggesting his diet or lifestyle."', '"MARLEY\'S GHOST":"MARLEY\'S GHOST is a manifestation that embodies the spirit of Jacob Marley, Scrooge\'s late business partner. This ghostly figure appears before Scrooge, carrying forward the essence and influence of Marley in the present. It serves as both a haunting presence and an anxiety-inducing force, reflecting on Scrooge\'s past actions and decisions."', '"HAUNTED HOUSE":"The location where ghosts are said to appear and haunt, in this context referring metaphorically to Scrooge\'s skepticism."', '"GHOST":"GHOST" is a supernatural entity that has appeared before Scrooge, claiming to be his late business partner, Jacob Marley. This ghostly figure introduces a mystical element into the narrative and appears alongside Scrooge in a somber room filled with plain deal forms and desks. The Ghost influences events and decisions in Scrooge\'s life, appearing without warning and impacting his environment, suggesting it has some kind of supernatural or magical influence. It represents a guiding force or spirit that provides moral guidance to someone. This entity from the past expresses regret about business and welfare, emphasizing their importance. The Ghost brings significant change to Scrooge\'s perspective and behavior, visiting him to question his beliefs and guide him through interactions with the unseen world. Representing Jacob Marley\'s spirit, it conveys messages to Scrooge, guiding him towards reflection on his past, present, and future experiences. Ultimately, this entity seems to be an unseen force that walks among humans, influencing Scrooge\'s thoughts and actions, guiding him in his journey of self-discovery and redemption.', '"JACOB MARLEY":"Jacob Marley is mentioned as being Scrooge\'s partner in life.")  ("entity"', '"SPIRITUAL EXISTENCE":"The concept of spirits walking the earth is introduced through the interaction between Scrooge and the Ghost."']}
19:56:14,148 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"MONEY-CHANGING HOLE":"This term likely refers to the same concept as \'counting-house\', emphasizing Scrooge\'s narrow focus on his business."', '"MESSAGES":', '"THE GHOST":"The Ghost" is a supernatural entity that appears before Scrooge, significantly impacting his mood and actions. This apparition communicates with Scrooge, sharing its experiences of remorse and continuous travel. The Ghost participates in an event organized by Scrooge, engaging with other characters such as Scrooge\'s niece. It serves as both an unseen entity entering through a double-locked door and interacting with Scrooge, as well as a representative conducting him through visions of his life, highlighting the past, present, and future. The Ghost forces Scrooge to confront various aspects of his existence through individual visits, guiding him towards self-reflection and transformation.', '"INDICTING":"The Ward might have justified indicting the Ghost for a nuisance due to its loud noise at night."', '"AGES OF INCESSANT LABOUR":"This concept refers to the long periods of continuous work by immortal creatures, which must pass into eternity before the good of this earth is all developed."', '"THE WARD":"The Ward is an organization that might have considered indicting something for being a nuisance."', '"JACOB":"Jacob is a character that appears within the narrative, engaging in dialogue with Scrooge. In one description, Jacob is portrayed as speaking directly to Scrooge and referencing three spirits, suggesting an interaction involving supernatural or mystical elements. The other description offers a more mundane perspective on Jacob\'s role, positing that he might be someone who was adept at business affairs, implying a connection to the practical world of commerce rather than the fantastical realm suggested by the first description. Given these descriptions, it seems Jacob could embody both a professional and possibly spiritual or magical aspect within the context of this text."', '"VISITS":"Visits refer to the series of ghostly appearances made by The Ghost to Scrooge over several nights."', '"PHANTOMS":"Phantoms are spirits or apparitions that wander, seeking to interfere in human affairs but have lost the ability to do so."', '"FIRST OF EXCHANGE":"The \'First of Exchange\' is a financial document that Scrooge needs to adhere to, causing him stress due to the potential consequences if he misses the deadline."', '"THE UNEARTHLY VISITOR":"The unearthly visitor is a mysterious figure that appears before Scrooge, drawing aside the curtains of his bed."', '"THE QUARTER":"The quarter refers to an event where time passes in increments, which Scrooge counts and anticipates."', '"GHOST OF CHRISTMAS PAST":"The Ghost of Christmas Past is a significant character in the narrative, appearing before Scrooge as an entity that serves multiple purposes. It acts as a reminder of his childhood experiences and influences him to reflect on his past actions, softening his demeanor. This ghost represents memories or past events associated with Christmas, evoking emotions and bringing back nostalgic tunes that resonate deeply with Scrooge\'s personal history. Essentially, the Ghost of Christmas Past embodies the essence of reminiscing about one\'s past during the festive season, impacting Scrooge\'s perspective on life."', '"SPIRIT":"SPIRIT" refers to a supernatural being or force that interacts with Scrooge, influencing his thoughts and actions. The Spirit appears to guide or influence Scrooge and observes the behavior of other people, providing answers to Scrooge\'s inquiries about peculiar flavors and usage. It communicates with Scrooge, offering guidance and insight, asking questions, demonstrating kindness towards poor men, revealing the horrors of humanity, guiding him through various scenes of Christmas, teaching lessons about generosity and humanity, representing a guiding or supernatural entity that influences his perspective on life, showing visions of past, present, and future, responding to Scrooge\'s questions, defending their intentions and clarifying actions, granting wishes or showing visions of the future, and possibly guiding him towards understanding human emotions and experiences. The Spirit is both metaphorical and a supernatural creature that shows off its powers, emphasizing the need for change, representing an entity that attaches importance to trivial conversations, and seems to be an entity that Scrooge interacts with, asking questions and granting wishes or showing visions of the future.', '"THE SPIRIT":"The Spirit" appears as a supernatural or mystical presence, touching Scrooge on the arm and pointing to his younger self, suggesting an otherworldly connection. This entity guides Scrooge through his past, present, and future, influencing his thoughts and memories, acting not just as an observer but also as an active participant in shaping Scrooge\'s understanding of his life. The Spirit stops beside a group of business men, initiating Scrooge\'s observation of the scene, indicating its role in bringing forth specific moments for reflection. Ultimately, "The Spirit" represents an entity that seeks to understand Scrooge\'s perspective on happiness and its sources, aiming to provide insights into what truly brings joy and fulfillment in life.', '"AN OPEN COUNTRY ROAD":"This is the setting where Scrooge experiences a sudden change in environment, symbolizing transformation."']}
19:56:14,150 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"FIELDS":"The fields on either side of the road represent aspects of life that Scrooge has forgotten or neglected."', '"MARKET-TOWN":"A market-town is described as a place Scrooge recognizes from his past, indicating its significance in the narrative."', '"MANSION":"The mansion is described as dull red brick with a weather-cock cupola on the roof and bell hanging in it. It\'s large but of broken fortunes."', '"ALI BABA":"Ali Baba is mentioned as someone who visited Scrooge in the past, possibly during Christmas time."', '"VALENTINE":"Valentine and his wild brother Orson are also referenced by Scrooge, indicating they were part of his past experiences or memories."', '"SULTAN\'S GROOM":"The Sultan\'s Groom is mentioned being turned upside down by the Genii, suggesting a humorous or fantastical event from Scrooge\'s memory."', '"CITY":"The City refers to the setting where Scrooge\'s business friends are located."', '"PARROT":"The Parrot is a living creature mentioned by Scrooge, indicating his interest in animals or perhaps pets."', '"FRIDAY":"Friday seems to be another character or entity that runs for his life, possibly related to the Parrot scenario."', '"CHRISTMAS CAROLLING BOY":"A boy singing a Christmas carol at Scrooge\'s door is mentioned as something he regrets not being able to help."', '"FAN":"Fan is Scrooge\'s younger sister who interacts with him and encourages him to return home."', '"HOME":"Home is portrayed as an idyllic sanctuary that fosters feelings of warmth and security for its inhabitants. For the child in question, home is a haven where they experience unparalleled bliss due to their father\'s gentle nature. This nurturing environment contributes significantly to the child\'s sense of well-being and happiness. Similarly, for Fan and Scrooge, home symbolizes the ultimate destination or goal that signifies safety and comfort amidst their interactions. It represents a place where they seek refuge from external challenges, emphasizing its role as a bastion of protection and tranquility."', '"THE BOY":"The boy, in this context, represents an individual who has a connection with Scrooge, engaging him in discussions regarding the poulterer\'s shop and the prized turkey. Following this interaction, the boy is later depicted returning to his home after being away for some time."', '"CHILD":"The child expresses joy at the prospect of staying permanently at home and having their father be kinder."', '"FATHER":"The father, accompanied by an individual bearing Christmas toys and presents, is making his way back home after completing his work duties. Amidst this festive atmosphere, his acts of kindness towards a child inspire the latter to inquire about the return of a missing person."', '"MASTER SCROOGE":"Master Scrooge is a character known for having a trunk tied on top of a chaise, which he uses as a mode of transportation. He often speaks about individuals possessing a large heart, highlighting his appreciation for generosity and kindness. Despite this, Master Scrooge finds himself being dragged towards the door by another person, indicating that while he may have a certain level of autonomy, there are instances where he is influenced or compelled to move along. This dynamic suggests a complex personality with both independent and dependent traits. Additionally, his encounters with the schoolmaster in the hall evoke feelings of dread, possibly hinting at past experiences or expectations that create anxiety when interacting with educational figures."']}
19:56:14,151 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"SCHOOLMASTER":"The schoolmaster appears in the hall and interacts with Master Scrooge, causing him distress."', '"VERIEST OLD WELL OF A SHIVERING BEST PARLOUR":"This refers to an extremely cold and uncomfortable room where Master Scrooge and his sister are taken by the schoolmaster."', '"DECANTER OF CURIOUSLY LIGHT WINE, AND A BLOCK OF CURIOUSLY HEAVY CAKE":"The schoolmaster serves these items to Master Scrooge and his sister as part of their interaction."', '"FEZZIWIG":"Fezziwig, as described here, is a character celebrated by apprentices and known for the impact he has on happiness. He is also portrayed as an old couple who organizes a vibrant party featuring music and food. Fezziwig\'s influence extends to being an organization represented by Mr. Fezziwig that hosts a dance party for his employees in their warehouse, further highlighting his role in fostering a lively atmosphere. Lastly, he is identified as an organization itself that conducts a spirited ball within its premises."', '"HILLI-HO":"Hilli-ho seems to be a character or individual who participates in the festivities at Fezziwig\'s organization."', '"EBENEZER":"Ebenezer is another character involved in the events at Fezziwig\'s organization, possibly participating in the festivities."', '"MRS. FEZZIWIG":"Mrs. Fezziwig leads or organizes the ball event at her husband\'s warehouse."', '"THE THREE MISS FEZZIWIGS":"These are female members of the Fezziwig family who participate in the festivities and possibly manage certain aspects of the organization."', '"THE SIX YOUNG FOLLOWERS":"These individuals follow or support Mrs. Fezziwig, participating in her organization\'s events."', '"THE HOUSEMAID":"The housemaid is a staff member at Fezziwig\'s organization who participates in the festivities and possibly helps manage household duties."', '"THE BAKER":"The baker collaborates with the housemaid, indicating they are part of the same organization or community."', '"THE COOK":"The cook is involved in Fezziwig\'s organization, possibly managing food preparation for events."', '"THE MILKMAN":"The milkman has a relationship with the cook at Fezziwig\'s organization, suggesting they are part of an interconnected community."', '"THE BOY FROM OVER THE WAY":"This individual is associated with Fezziwig\'s organization but comes from another location, possibly contributing to or benefiting from its activities."', '"MISS FEZZIWIGS":"The Miss Fezziwigs are part of an organization that includes various employees and family members, indicating a familial business environment."', '"FEZZIWIG\'S BUSINESS":"Fezziwig\'s Business is the collective entity that employs young men and women as well as has connections with local businesses like bakeries and milkmen."']}
19:56:14,152 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"THE DANCE":"The Dance is a social event where various members of Fezziwig\'s organization participate, highlighting the communal nature of their workplace."', '"EMPLOYEES":', '"FIDDLER":"The fiddler is an artful musician who plays music at the party, contributing to its lively atmosphere."', '"PARTY":"A party is being held where various activities like dancing, eating and drinking are taking place."', '"DANCING":"Dancing is one of the activities happening at the party."', '"MUSIC":"Music provided by the fiddler enhances the atmosphere of the party."', '"FOOD":"Food supplies like Roast, Boiled meat, mince-pies and beer are being served at the party."', '"YOUNG GIRL":"The young girl sitting by Scrooge\'s side shows tears in her eyes, suggesting she feels displaced by Scrooge\'s new idol."', '"IDOL":"An \'idol\' refers to a new object of Scrooge\'s affection or focus, which has replaced the young girl in his life."', '"SHE":"SHE" refers to two distinct characters with contrasting roles and motivations. The first character discusses the transformation of her partner\'s values, initially centered around nobler aspirations but later shifting towards a focus on wealth acquisition. This suggests a narrative where personal growth or societal pressures influence one\'s priorities from idealistic goals to more materialistic ones.\n\nThe second character is portrayed as someone who releases Scrooge, presumably with the hope that he will find happiness in his current life circumstances rather than pursuing external changes or improvements. This implies a belief in contentment and satisfaction within one\'s existing situation, advocating for gratitude and appreciation of what one already has over seeking additional wealth or status.\n\nIn summary, "SHE" embodies contrasting perspectives on personal value transformation and contentment with the present state of affairs. The first character highlights the shift from idealistic aspirations to material pursuits, while the second character emphasizes finding happiness in the life choices made, suggesting a preference for inner fulfillment over external achievements.', '"HE":"He" refers to a character who embodies several distinct yet interconnected aspects in this narrative. Initially, he is portrayed as an individual who was anticipating something significant but experienced a sense of surprise when nothing materialized, suggesting a discrepancy between his expectations and the outcome.\n\nSubsequently, "He" transitions into another character whose values are under scrutiny, particularly noting his evolving perspective towards prioritizing gain over other aspirations or hopes. This shift in focus implies a transformation within his priorities that may have significant implications for his future actions or decisions.\n\nLastly, "He" emerges as the central subject of the text, engaging in introspection and dialogue about his feelings, specifically regarding her. He appears to be reflecting on their past relationship, expressing impatience and contemplating the possibility of rekindling it by seeking her out again. This segment highlights a personal narrative that intertwines with themes of reflection, emotion, and potential reconciliation.\n\nIn summary, "He" is characterized as an individual who experiences surprise, undergoes a shift in values towards prioritizing gain, and reflects on past relationships, considering the possibility of reconnection. These descriptions collectively paint a picture of a complex character navigating through emotional and personal transformations within the context of his interactions and expectations.', '"POVERTY":"Poverty is mentioned as a hard condition and contrasted with the pursuit of wealth."', '"WEALTH":"Wealth is described as something that one fears too much, suggesting it\'s condemned or feared by society."', '"WORLD":"The world represents societal norms and values which are seen to reproach those who pursue wealth."', '"CONTRACT":"A contract is mentioned that was made when both parties were poor, suggesting a change in circumstances or values over time."', '"MEMORY":"Memory serves as the central theme throughout this text, highlighting Scrooge\'s introspection on his deeds and their repercussions. The notion of memory significantly contributes to his contemplation over his past actions and decisions."']}
19:56:14,153 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"PAST ACTIONS":"Scrooge reflects on his past actions, particularly those related to gain and love."', '"RELEASE":', '"TORTURE":"Torture here refers to the intense emotional experience Scrooge undergoes as he relives past events."', '"GROUP":"A group of individuals, potentially comprising children, have assembled to welcome back their father. This gathering is characterized by a lively atmosphere, with the attendees appearing flushed and displaying a high level of enthusiasm, suggesting that they are an energetic and excited crowd."', '"BELLE":"Belle is Scrooge\'s wife who is mentioned by her husband in relation to his old friend Mr. Scrooge."', '"EXTINGUISHER-CAP":"The Extinguisher-cap is an object used by Scrooge in an attempt to hide the light of the Ghost."', '"TURKEYS, GEESE, GAME, POULTRY, BRAWN, GREAT JOINTS OF MEAT, SUCKING-PIGS, LONG WREATHS OF SAUSAGES, MINCE-PIES, PLUM-PUDDINGS, BARRELS OF OYSTERS, RED-HOT CHESTNUTS, CHERRY-CHEEKED APPLES, JUICY ORANGES, LUSCIOUS PEARS, IMMENSE TWELFTH-CAKES, AND SEETHING BOWLS OF PUNCH":"A variety of festive food items are described as being heaped up on the floor, forming a kind of throne for the Ghost. This suggests an abundance and richness that contrasts with Scrooge\'s previous life."', '"THE PHANTOM":"The Phantom" in this context can refer to two distinct entities within the narrative. Initially described as an entity that Scrooge deeply desired to uncover or remove the veil from, implying a hidden truth or mystery that Scrooge was unable to influence or control due to his lack of power over it. This description suggests "The Phantom" embodies some form of concealed reality or secret that Scrooge yearns to reveal.\n\nConversely, another interpretation of "The Phantom" is associated with the Ghost of Christmas Present, one among several spirits that visit Scrooge during the festive period of Christmas Eve and Christmas Day. In this context, "The Phantom" symbolizes a guiding spirit who helps Scrooge understand the current state of affairs in his life and encourages him to embrace the warmth and joy of the holiday season.\n\nIn summary, "The Phantom" can represent either an unattainable truth or mystery that Scrooge seeks to uncover or it could denote the Ghost of Christmas Present, a spirit that enlightens Scrooge about the present state during the festive period. The contradictory descriptions are reconciled by understanding them as two different entities within the narrative: one being a metaphor for hidden truths and the other symbolizing a guiding force in the celebration of Christmas.', '"FAMILY":"The concept of family is central in discussions between the Spirit and Scrooge, highlighting themes of kinship and responsibility."', '"THE GHOST OF CHRISTMAS PRESENT":"The Ghost of Christmas Present serves as a pivotal figure in guiding Ebenezer Scrooge towards transformation by imparting lessons that significantly influence his subsequent actions. This entity plays a crucial role in Scrooge\'s journey, marking another significant milestone where he experiences the essence of joy and generosity."', '"CHRISTMAS MORNING":"Christmas morning refers to the time when Scrooge and the Ghost are standing in the city streets on."', '"PEOPLE":People are central figures in this scenario, showcasing the dynamic nature of urban life as they hurry to and fro on the streets. This representation highlights the bustling pace characteristic of city dwellers.\n\nIn another depiction, people are shown engaging in a unique community activity during snowy weather conditions. They are depicted shovelling away snow from house-tops with joviality and glee, suggesting not only their resilience but also their spirit of camaraderie amidst challenging circumstances.\n\nSimultaneously, there is an emphasis on the collective effort of individuals working together to clean snow from pavements and houses. This scene portrays people as active participants in community maintenance activities, emphasizing cooperation and shared responsibility within a neighborhood during winter conditions.\n\nIn summary, these descriptions collectively paint a picture of people as central actors in urban environments, characterized by their dynamism, resilience, and communal spirit when faced with challenges such as snowy weather.', '"FRUITERERS":"Fruiterers are depicted as having shops that are still half open, indicating their role in selling fresh produce."', '"PUDDING SELLERS":"Pudding sellers are mentioned alongside other vendors, suggesting they sell desserts or pastries."', '"CHESTNUTS":"Round, pot-bellied baskets of chestnuts are described as being displayed in the shops."', '"SPANISH ONIONS":"Ruddy, brown-faced Spanish onions are mentioned for their size and growth, indicating they are a fresh produce item."']}
19:56:14,153 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"MISTLETOE":"Mistletoe is described as being hung up in the shops, suggesting it\'s sold during festive seasons."', '"PEARS AND APPLES":"Pears and apples are clustered high in blooming pyramids, indicating their abundance and freshness."', '"GRAPES":"Grapes are mentioned as being hung from conspicuous hooks for free tasting by passersby."', '"FILBERTS":"Filberts are described as mossy and brown, recalling ancient walks among woods, indicating they\'re a seasonal product."', '"NORFOLK BIFFINS":"Norfolk Biffins are mentioned alongside oranges and lemons, suggesting they\'re sold together or in the same shop."', '"THE GROCERS\'":"The Grocers\' refers to a specific store or establishment that is nearly closed but still has some activity happening."', '"SCALES":"Scales are being used in the context of weighing goods for sale at The Grocers\'."', '"TWINE AND ROLLER":"Twine and a roller are mentioned as part of the process of packaging or handling goods."', '"CANISTERS":"Canisters are being used to store and display items like tea and coffee."', '"BLENDED SCENTS":"The blended scents of tea and coffee refer to the pleasant aromas that customers might experience."', '"RAISINS":"Raisins are mentioned as one of the items available for sale at The Grocers\'."', '"ALMONDS":"Almonds are another food item being sold, noted for their extreme whiteness."', '"STICKS OF CINNAMON":"Cinnamon sticks are mentioned as a spice available at The Grocers\'."', '"OTHER SPICES":"This refers to various other spices that might be sold at the store."', '"CANDIED FRUITS":"Candied fruits are mentioned as another type of food available for sale."', '"GROCER":"The grocer is a business owner or manager who runs the store where customers purchase goods." ) ("entity"']}
19:56:14,153 datashaper.workflow.workflow ERROR Error executing verb "text_embed" in create_final_entities: 'coroutine' object has no attribute 'choices'
Traceback (most recent call last):
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/datashaper/workflow/workflow.py", line 415, in _execute_verb
    result = await result
             ^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/verbs/text/embed/text_embed.py", line 105, in text_embed
    return await _text_embed_in_memory(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/verbs/text/embed/text_embed.py", line 130, in _text_embed_in_memory
    result = await strategy_exec(texts, callbacks, cache, strategy_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py", line 62, in run
    embeddings = await _execute(llm, text_batches, ticker, semaphore)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py", line 106, in _execute
    results = await asyncio.gather(*futures)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py", line 100, in embed
    chunk_embeddings = await llm(chunk)
                       ^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py", line 50, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py", line 54, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_completion_llm.py", line 43, in _execute_llm
    return completion.choices[0].text
           ^^^^^^^^^^^^^^^^^^
AttributeError: 'coroutine' object has no attribute 'choices'
19:56:14,158 graphrag.index.reporting.file_workflow_callbacks INFO Error executing verb "text_embed" in create_final_entities: 'coroutine' object has no attribute 'choices' details=None
19:56:14,159 graphrag.index.run.run ERROR error running workflow create_final_entities
Traceback (most recent call last):
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/run/run.py", line 227, in run_pipeline
    result = await _process_workflow(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/run/workflow.py", line 91, in _process_workflow
    result = await workflow.run(context, callbacks)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/datashaper/workflow/workflow.py", line 369, in run
    timing = await self._execute_verb(node, context, callbacks)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/datashaper/workflow/workflow.py", line 415, in _execute_verb
    result = await result
             ^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/verbs/text/embed/text_embed.py", line 105, in text_embed
    return await _text_embed_in_memory(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/verbs/text/embed/text_embed.py", line 130, in _text_embed_in_memory
    result = await strategy_exec(texts, callbacks, cache, strategy_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py", line 62, in run
    embeddings = await _execute(llm, text_batches, ticker, semaphore)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py", line 106, in _execute
    results = await asyncio.gather(*futures)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py", line 100, in embed
    chunk_embeddings = await llm(chunk)
                       ^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py", line 50, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py", line 54, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pcuser/anaconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_completion_llm.py", line 43, in _execute_llm
    return completion.choices[0].text
           ^^^^^^^^^^^^^^^^^^
AttributeError: 'coroutine' object has no attribute 'choices'
19:56:14,161 graphrag.index.reporting.file_workflow_callbacks INFO Error running pipeline! details=None
19:56:14,176 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"BAKER\'S SHOPS":"Baker\'s shops are places where people go to get their dinners, indicating a festive event."', '"CHRISTMAS DAY":"Christmas Day is a significant celebration marked by acts of kindness, sharing, and festivities among people, regardless of their geographical distances. This day holds great importance as it was during this event that Scrooge experienced his transformation after being visited by the Spirits. Additionally, Christmas Day serves as the backdrop for an intriguing flavor attributed to Spirit\'s torch, adding a unique dimension to its celebration."', '"MANY WORLDS":"This concept refers to a vast universe or multitude of universes, which the Spirit operates within."', '"DINNERS":"The discussion revolves around the impact on dinners given on specific days, particularly focusing on those that might be less affluent."', '"BELINDA CRATCHIT":"Belinda Cratchit is one of Mrs. Cratchit\'s daughters who assists her mother laying the cloth."', '"MASTER PETER CRATCHIT":"Master Peter Cratchit, another member of the Cratchit family, participates in preparing food for their celebration."', '"BOB":"Bob is a character who has been portrayed in various contexts. He admires the cooked goose, expressing disbelief that such a goose has ever been cooked before. Bob also expresses his feelings about being known as a good husband and offers help to others. He has been Tim\'s blood-horse all the way from church and is disappointed that they didn\'t come upon Christmas Day. Bob shares an event he experienced with others and mentions Christmas Day and the Founder of the Feast, showing familiarity with these concepts. It seems that Bob might be involved in cooking or preparing food as he nearly choked on his collars while blowing fire. He wishes his wife could have gone to see the green place where he works on Sunday and feels emotional about this situation. Additionally, Bob is proud of making lame beggars walk and blind men see but also feels a sense of guilt."', '"MARTHA":"MARTHA, in the context provided, seems to embody different facets of personality and occupation. Initially, Martha appears as someone who might be part of Mrs. Cratchit\'s household, possibly responding to her inquiries or concerns. This suggests that she could be a relative or an employee within the family setting.\n\nIn another description, Martha is portrayed as a character who tends to hide upon the arrival of her father, indicating a sense of shyness or perhaps fearfulness in social situations. However, despite this initial reticence, she eventually emerges from hiding to avoid disappointing him, showcasing her caring nature and desire for familial harmony.\n\nLastly, there\'s an insight into Martha\'s professional life as an apprentice at a milliner\'s. This description highlights her involvement in the fashion industry, sharing her daily work routine and experiences with others, which suggests that she is actively learning and contributing to the field of hat-making or related crafts."\n\nThis summary consolidates the diverse descriptions of "MARTHA" into a coherent narrative, addressing each aspect while resolving any contradictions.', '"THE TWO YOUNG CRATCHITS":"These are likely children who are excited about something, possibly a goose, which suggests they\'re part of the family and involved in holiday preparations."', '"TINY TIM":"TINY TIM is a notable character recognized for his unique condition that influences those around him. He possesses a plaintive voice which he uses to sing beautifully, symbolizing happiness despite the family\'s lack of material possessions. As a child figure, Tiny Tim\'s memory and impact are acknowledged by other characters. He is specifically known as Bob Cratchit\'s son, carrying a little crutch and having his limbs supported by an iron frame."', '"THE CRATCHIT FAMILY":"The Cratchit family consists of Bob and Mrs. Cratchit along with their children, who gather around the hearth to eat dinner."', '"DINNER":"Dinner is being prepared and served by Mrs. Cratchit, a significant event in this scene."', '"FIRE":"Fires are depicted as sources of warmth and light, symbolizing coziness and comfort in contrast to the coldness outside."', '"MINERS":"Miners are living in a place described by Scrooge as bleak and deserted."', '"BLEAK AND DESERT MOOR":"The location is characterized as a barren, deserted area with large stones and no vegetation except moss, furze, and coarse grass."', '"OLD MAN":"The old man is singing a Christmas song to others in a barren waste, showing his joy despite harsh conditions."']}
19:56:14,176 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"MOOR":"The moor is a location where the old man sings Christmas songs, and Scrooge\'s journey takes place."', '"LIGHTHOUSE":"A solitary lighthouse stands on a reef of sunken rocks, which is described as being built upon a \'dismal\' location."', '"CHRISTMAS SONG":', '"SOLITARY LIGHTHOUSE":"The solitary lighthouse stands alone on a reef off the coast, symbolizing isolation and solitude."', '"TWO MEN":"Two men are watching the light at the lighthouse, sharing a moment of camaraderie despite their isolation."', '"BLACK AND HEAVING SEA":"The Black and Heaving Sea is a metaphorical representation of the unknown or the vastness of existence."', '"SCROOGE\'S NEPHEW":"Scrooge\'s nephew is portrayed as a character who enjoys laughing heartily and spreading joy despite others\' disapproval. He also expresses sympathy for the wealthy individual, finding amusement in their situation. In one instance, he shares his opinion about someone believing that Christmas is a \'humbug\'. Additionally, it is mentioned that he is part of a collaborative relationship with Topper, indicating a potentially manipulative or deceptive partnership. Lastly, he is noted to have an opinion on bachelorhood and housekeepers."', '"TOPPER":"\\"Topper\\", in this context, represents an individual who might be perceived as either a genuine blind person or someone involved in some form of collusion with another character (Scrooge\'s nephew), suggesting elements of deceit or trickery. However, there is also the aspect that \\"Topper\\" comes from a musical family, implying proficiency and talent in singing and playing music."', '"MUSIC SESSION":"A music session takes place where the family sings glees or catches, with Topper contributing in the bass."', '"HARMONY":"The concept of harmony is present as they sing together, showing unity and enjoyment."', '"FOUNDER":"The Founder is portrayed as being young himself, suggesting they might be inexperienced or perhaps still in their formative years."', '"GAME AT BLIND MAN\'S-BUFF":"A game of \'blind man\'s buff\' was played, which could symbolize a playful or naive approach to certain situations."', '"GHOST OF CHRISTMAS PRESENT":"The Ghost of Christmas Present represents an unseen force or influence in the situation, possibly guiding or observing events from afar."', '"COLLUSION WITH SCROOGE\'S NEPHEW":', '"OBSERVATION":', '"HIS NIECE":"Scrooge\'s niece participates in games and activities during the event hosted by Scrooge."']}
19:56:14,177 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"OLD JOE":"Old Joe is an older character with multiple roles and connections. He reflects on his past generosity and contemplates its potential consequences, showcasing his introspective nature. Old Joe also expresses concern about the man\'s death and burial, indicating a sense of responsibility or empathy towards others. In another context, he is involved in examining and appraising items produced by an individual, suggesting expertise in evaluation or. Additionally, Old Joe plays a part in dialogue as one of several characters who produce a flannel bag containing money, highlighting his involvement in transactions or financial dealings. Lastly, he owns a shop where three individuals from different professions coincidentally meet, demonstrating his role as a community hub or business owner."', '"THE OLD MAN":"The old man is a character who speaks and acts in this text, suggesting he plays a significant role.")  ("entity"', '"MRS. DILBER":"MRS. DILBER" is portrayed as a character within this narrative, engaging in dual personas. Initially, she emerges as an insightful figure, discussing the concept of judgment following someone\'s demise. This dimension to her character highlights her spiritual or philosophical understanding, possibly reflecting on moral implications after death.\n\nSubsequently, Mrs. Dilber transitions into a more empathetic and accepting role. She is depicted laughing and in agreement with another woman, suggesting that she not only understands but also embraces the situation at hand. Her laughter might indicate a sense of relief, acceptance, or even humor in dealing with complex human emotions or circumstances.\n\nIn summary, "Mrs. Dilber" embodies both intellectual depth and emotional resilience, navigating through discussions on spiritual judgment while offering support and understanding to others facing challenging situations.', '"THE WOMAN":"The Woman" is portrayed as an individual with strong convictions and emotions, as she expresses her wish for a heavier judgment on another character, suggesting that she feels strongly about the situation at hand. She also appears to be involved in dialogue, laughing alongside Scrooge and making comments about the deceased person, indicating her presence in a social context where death is being discussed. Furthermore, "The Woman" demonstrates a sense of moral responsibility by speaking out against the actions of a deceased man, advocating for self-care principles and questioning why he didn\'t have someone to look after him when alive. This portrayal highlights her concern for ethical conduct and personal well-being in life and beyond.', '"THE LAUNDRESS":"The laundress agrees with Mrs. Dilber\'s statement about the judgment on the dead man, showing solidarity."', '"THE DECEASED MAN":"The deceased man is a character who has passed away and whose actions are being questioned by the woman."', '"ODDS":"Odds refer to the situation or circumstances that Mrs. Dilber, the laundress, and the woman are discussing."', '"THE MAN IN FADED BLACK":"The man in faded black produces some of his \'plunder\' which includes a seal or two, a pencil-case, a pair of sleeve-buttons, and a brooch of no great value."', '"HER FRIENDS":"Her friends are a group that would not allow her to leave without taking something valuable.") ("entity"', '"THE FIRST WOMAN":"The first woman is another character who seeks to retrieve her belongings from Old Joe."', '"ACCOUNT":"An account of transactions or dealings between individuals is mentioned."', '"WOMAN":"The woman is another character who responds to Joe\'s questions and statements."', '"FORTUNE":"Fortune refers to the idea of making wealth or success, which Joe believes the woman was born to achieve."', '"BLANKETS":"Blankets are items that the woman mentions as belonging to the deceased, suggesting she took care of his belongings."', '"OIL":"Oil is mentioned in relation to a potential spill or mess on blankets, indicating some action taken by Joe."', '"DIALOGUE":"A conversation or dialogue takes place between Old Joe, The Woman, and possibly others which Scrooge listens to with horror."']}
19:56:14,177 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"EVENT":"This refers to an unspecified gathering or party where games such as \'forfeits\', \'How, When, and Where\' are played."', '"GAME":"A game is being played among the guests which Scrooge joins enthusiastically."', '"YES AND NO GAME":"Yes and No is a guessing game played by Scrooge\'s nephew where he has to think of something based on questions answered with yes or no."', '"FRED":"FRED is portrayed as an individual who encounters Scrooge and appears to have a familiar connection with him. He is depicted as one of the characters who engages in interactions with Scrooge, asking questions about him and suggesting that they should drink his uncle\'s health. Fred exhibits surprise and excitement upon seeing Scrooge at his house, which suggests a close relationship or acquaintance between them. Despite not taking anything from Scrooge directly, Fred wishes him \'merry Christmas\', indicating a friendly disposition towards the character."', '"SISTER":"The sister is also involved in the interaction with Scrooge, identifying him as the subject of their amusement."', '"MULLED WINE":"Mulled wine is mentioned as something ready to be consumed, suggesting a festive or celebratory atmosphere."', '"UNCONSCIOUS COMPANY":"The unconscious company refers to Scrooge\'s business or organization which is not aware of its transformation due to the influence of the Ghost.") ("entity"', '"MONSTERS":"Monsters are described as being half so horrible and dread compared to what angels might have represented."', '"IGNORANCE":"Ignorance is one of the children shown by the Spirit, representing a lack of knowledge or understanding."', '"WANT":"Want is another child shown by the Spirit, symbolizing a state of lacking basic needs or resources."', '"BUSINESS MEN":"A group of business men are conversing and discussing about someone who has died. They are characterized by their actions like chinking money in their pockets and taking snuff."', '"THE DEAD PERSON":"An event where a person\'s death is being discussed among the business men, which seems to be unexpected or surprising for some of them."', '"INITIATION":', '"THE RED-FACED GENTLEMAN":"The red-faced gentleman is characterized by a pendulous excrescence on his nose that shakes like the gills of a turkey-cock.") ("entity"', '"OLD SCRATCH":"Old Scratch is an unspecified entity that has obtained something, possibly related to the conversation between two business men.") ("entity"', '"DEATH OF JACOB":"The Death of Jacob is a past event that does not seem to relate directly to the current conversation between the two characters."']}
19:56:14,178 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': ['"DEATH":"Death is described as a concept that can set up its altar and dress it with terrors at command, symbolizing dominion over life and death."', '"THE LOVED, REVERED, AND HONOURED HEAD":"This refers to the head of someone who was loved, revered, and honored but cannot be touched or moved by Death."', '"TOWN":"The town is the setting where this emotional event occurs, likely involving a community response to someone\'s death."', '"MOTHER AND HER CHILDREN":"This organization represents a family unit experiencing distress due to the death of another person in their community."', '"HIS":"He is the subject of this text who seems to have received some serious news which he feels ashamed about and struggles to share.") ("entity"', '"HALF-DRUNKEN WOMAN":"The half-drunk woman is a character who provided truthful information about the ill state of another person.") ("entity"', '"THE MOTHER":"The mother is a character who notices changes in her husband\'s behavior and discusses them with others."', '"CRATCHIT\'S WIFE":"Cratchit\'s wife is another character who confirms the observations made by the mother about Tiny Tim."', '"PETER":"Peter is a character known for his frequent visits to the place in question. He also acknowledges that his father walks with Tiny Tim very fast. This might indicate Peter\'s involvement in family activities or responsibilities. Additionally, there are speculations about Peter setting up for himself or getting into a better situation, which could suggest personal growth or changes in his life circumstances. Furthermore, it is mentioned that Peter shakes hands with Scrooge, implying a professional or social connection between them."', '"THE MOTHER\'S HUSBAND/FATHER":"The mother\'s husband/father is a character whose walking patterns are being observed by his family, indicating potential health issues."', '"SPIRIT OF TINY TIM":"The Spirit of Tiny Tim represents the essence and memory of Tiny Tim in Scrooge\'s visions."', '"LITTLE BOB":"Little Bob expresses happiness and receives multiple kisses from other characters."', '"TWO YOUNG CRATCHITS":"Two young Cratchits are also mentioned kissing Scrooge, indicating a familial or friendly relationship."', '"SPECTRE":"The term \'Spectre\' seems to be used interchangeably with the Ghost of Christmas Yet to Come in this context."', '"CHRISTMAS YET TO COME":"Christmas Yet to Come is a future event that Scrooge wishes to see through the Spirit\'s vision."', '"NEGLECTED GRAVE":"The Neglected Grave is a symbolical place where Scrooge discovers his own name EBENEZER SCROOGE, marking a significant realization in the story."']}
19:56:14,185 graphrag.index.cli ERROR Errors occurred during the pipeline run, see logs for more details.
